{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data import * \n",
    "from lda_trial import *\n",
    "\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = IMDBDataset('train', data_limit=20_000)\n",
    "validset = IMDBDataset('valid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 20000\n",
    "\n",
    "for k in [2]:\n",
    "    print(f'{k}.')\n",
    "    trained_model, final_metric = tp_one_trial(trainset, 'lda', k, n, \n",
    "                                              3, 5,  # args.burn_in,\n",
    "                                              max_iter=20, stop_increase=5, metric='ll')\n",
    "\n",
    "    lda_x, lda_y = load_LDA_data_batch(trained_model, trainset)\n",
    "    model = LinearSVC()\n",
    "    model.fit(lda_x, lda_y)\n",
    "\n",
    "    prediction = model.predict(lda_x)\n",
    "    ground_truth = lda_y\n",
    "    print(f'Train: {100*accuracy_score(prediction, ground_truth):6.5f}%')\n",
    "    lda_x, lda_y = load_LDA_data_batch(trained_model, validset)\n",
    "\n",
    "    prediction = model.predict(lda_x)\n",
    "    ground_truth = lda_y\n",
    "    print(f'Test: {100*accuracy_score(prediction, ground_truth):6.5f}%')\n",
    "    print('-' * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse, os, time, pickle\n",
    "\n",
    "import tomotopy as tp\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from data import *\n",
    "from util import *\n",
    "\n",
    "\n",
    "def tp_one_trial(dataset, model_type, topic_size, sample_size, min_cf=3, rm_top=5,\n",
    "             max_iter=1000, min_iter=None, checkpoint=None, stop_increase=1, metric='ll'):\n",
    "    assert model_type in ['lda', 'ctm', 'slda', 'hdp'], f'invalid `model_type`: {model_type}...'\n",
    "    assert metric in ['ll', 'pp'], f'invalid `metric`: {metric}...'\n",
    "    if model_type == 'lda':\n",
    "        model = tp.LDAModel(k=topic_size, tw=tp.TermWeight.ONE, min_cf=min_cf, rm_top=rm_top)\n",
    "    if model_type == 'ctm':\n",
    "        model = tp.CTModel(k=topic_size, tw=tp.TermWeight.ONE, min_cf=min_cf, rm_top=rm_top)\n",
    "    if model_type == \"slda\":\n",
    "        model = tp.SLDAModel(k=topic_size,vars=\"b\", tw=tp.TermWeight.ONE, min_cf=min_cf, rm_top=rm_top)\n",
    "    if model_type == 'hdp':\n",
    "        model = tp.HDPModel(initial_k=topic_size, tw=tp.TermWeight.ONE, min_cf=min_cf, rm_top=rm_top)\n",
    "    sample_size = min(sample_size, len(dataset))\n",
    "    \n",
    "    max_iter = max_iter * sample_size * topic_size // 2000  # ensure the number of iterations increases with the size of sample\n",
    "    model.burn_in = max_iter // 5  # set burn-in: 20 percent of max iterations\n",
    "\n",
    "    for i in range(sample_size):\n",
    "        doc, label = dataset[i]\n",
    "        if model_type == \"slda\":\n",
    "            model.add_doc(doc,[float(label),])\n",
    "        else:\n",
    "            model.add_doc(doc)\n",
    "\n",
    "    if min_iter is None:\n",
    "        min_iter = max_iter // 5\n",
    "    if checkpoint is None:\n",
    "        checkpoint = max_iter // 5\n",
    "\n",
    "    model.train(min_iter)\n",
    "\n",
    "    pre_metric = - np.infty\n",
    "    stop_increase_cnt = 0.\n",
    "    cur_metric = 0.\n",
    "    for i in range(1, max_iter+1):\n",
    "        model.train(1)\n",
    "        # Metric is always larger, better\n",
    "        if metric == 'll':\n",
    "            cur_metric += model.ll_per_word\n",
    "        if metric == 'pp':\n",
    "            cur_metric += - model.perplexity  # smaller perplexity is better.\n",
    "\n",
    "        if i % checkpoint == 0:\n",
    "            cur_metric /= checkpoint\n",
    "            print(f'Current loss: {cur_metric:.5f}')\n",
    "            if cur_metric >= pre_metric:\n",
    "                pre_metric = cur_metric\n",
    "            else:\n",
    "                stop_increase_cnt += 1\n",
    "            cur_metric = 0.\n",
    "\n",
    "        if stop_increase_cnt >= stop_increase:\n",
    "            break\n",
    "\n",
    "    final_metric = model.perplexity if metric == 'pp' else model.ll_per_word\n",
    "\n",
    "    print(f'Trial iterations: {i + min_iter}.')\n",
    "    return model, final_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current loss: -7.57064\n",
      "Current loss: -7.55045\n",
      "Current loss: -7.53612\n",
      "Current loss: -7.52850\n",
      "Current loss: -7.52232\n",
      "Trial iterations: 120.\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "n = 5000\n",
    "k = 2\n",
    "trained_model, final_metric = tp_one_trial(trainset, 'hdp', k, n, \n",
    "                                              3, 5,  # args.burn_in,\n",
    "                                              max_iter=20, stop_increase=5, metric='ll')\n",
    "print(trained_model.live_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current loss: -7.64659\n",
      "Current loss: -7.62968\n",
      "Current loss: -7.61834\n",
      "Current loss: -7.61085\n",
      "Current loss: -7.60513\n",
      "Trial iterations: 180.\n",
      "18\n"
     ]
    }
   ],
   "source": [
    "n = 5000\n",
    "k = 3\n",
    "trained_model, final_metric = tp_one_trial(trainset, 'hdp', k, n, \n",
    "                                              3, 5,  # args.burn_in,\n",
    "                                              max_iter=20, stop_increase=5, metric='ll')\n",
    "print(trained_model.live_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current loss: -7.58315\n",
      "Current loss: -7.54795\n",
      "Current loss: -7.53424\n",
      "Current loss: -7.52699\n",
      "Current loss: -7.52207\n",
      "Trial iterations: 300.\n",
      "16\n"
     ]
    }
   ],
   "source": [
    "n = 5000\n",
    "k = 5\n",
    "trained_model, final_metric = tp_one_trial(trainset, 'hdp', k, n, \n",
    "                                              3, 5,  # args.burn_in,\n",
    "                                              max_iter=20, stop_increase=5, metric='ll')\n",
    "print(trained_model.live_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current loss: -7.55773\n",
      "Current loss: -7.54378\n",
      "Current loss: -7.53730\n"
     ]
    }
   ],
   "source": [
    "n = 5000\n",
    "k = 10\n",
    "trained_model, final_metric = tp_one_trial(trainset, 'hdp', k, n, \n",
    "                                              3, 5,  # args.burn_in,\n",
    "                                              max_iter=20, stop_increase=5, metric='ll')\n",
    "print(trained_model.live_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
